{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43966f7f",
   "metadata": {},
   "source": [
    "# LangChain with PostgreSQL pgvector\n",
    "\n",
    "This notebook demonstrates how to use LangChain's pgvector integration for RAG applications with PostgreSQL and pgvector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffe60eb",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d5e38de",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_community'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpsycopg2\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PGVector\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument_loaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TextLoader\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_community'"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import psycopg2\n",
    "from langchain_community.vectorstores import PGVector\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be60c8b8",
   "metadata": {},
   "source": [
    "## 2. Database Connection Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800ffb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database configuration\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'port': '5432',\n",
    "    'database': 'rag_db',\n",
    "    'user': 'rag_user',\n",
    "    'password': 'rag_password'\n",
    "}\n",
    "\n",
    "# Create connection string for LangChain\n",
    "CONNECTION_STRING = f\"postgresql+psycopg2://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "\n",
    "print(\"‚úÖ Database connection string configured\")\n",
    "print(f\"Connection: {CONNECTION_STRING.replace(DB_CONFIG['password'], '***')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9aba0b",
   "metadata": {},
   "source": [
    "## 3. Initialize Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb0a502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Use OpenAI embeddings (requires API key)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key-here\"\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Option 2: Use local sentence transformers (free, no API key needed)\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "print(\"‚úÖ Embeddings initialized\")\n",
    "print(f\"Model: {embeddings.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c141220a",
   "metadata": {},
   "source": [
    "## 4. Create PGVector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e01889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PGVector store\n",
    "try:\n",
    "    vectorstore = PGVector(\n",
    "        connection_string=CONNECTION_STRING,\n",
    "        embedding_function=embeddings,\n",
    "        collection_name=\"langchain_docs\",\n",
    "        pre_delete_collection=True  # Delete existing collection if it exists\n",
    "    )\n",
    "    print(\"‚úÖ PGVector store created successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating vector store: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aa7b8b",
   "metadata": {},
   "source": [
    "## 5. Add Documents to Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c733205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample documents\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"PostgreSQL is a powerful, open source object-relational database system with over 35 years of active development.\",\n",
    "        metadata={\"source\": \"postgres_wiki\", \"topic\": \"database\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"pgvector is a PostgreSQL extension for vector similarity search. It supports L2 distance, inner product, and cosine distance.\",\n",
    "        metadata={\"source\": \"pgvector_docs\", \"topic\": \"vector_search\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"LangChain is a framework for developing applications powered by language models. It provides components for working with LLMs.\",\n",
    "        metadata={\"source\": \"langchain_docs\", \"topic\": \"framework\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"RAG (Retrieval-Augmented Generation) combines retrieval from a knowledge base with generative AI to provide more accurate responses.\",\n",
    "        metadata={\"source\": \"ai_concepts\", \"topic\": \"rag\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Vector embeddings are numerical representations of text that capture semantic meaning. They enable similarity search and clustering.\",\n",
    "        metadata={\"source\": \"ml_concepts\", \"topic\": \"embeddings\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "# Add documents to vector store\n",
    "try:\n",
    "    vectorstore.add_documents(documents)\n",
    "    print(f\"‚úÖ Added {len(documents)} documents to vector store\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error adding documents: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be791cdd",
   "metadata": {},
   "source": [
    "## 6. Perform Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e50ecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform similarity search\n",
    "query = \"What is vector similarity search?\"\n",
    "\n",
    "try:\n",
    "    results = vectorstore.similarity_search(query, k=3)\n",
    "    \n",
    "    print(f\"üîç Query: '{query}'\")\n",
    "    print(f\"üìä Found {len(results)} similar documents:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, doc in enumerate(results, 1):\n",
    "        print(f\"{i}. Similarity Score: {doc.metadata.get('score', 'N/A')}\")\n",
    "        print(f\"   Content: {doc.page_content}\")\n",
    "        print(f\"   Source: {doc.metadata.get('source', 'Unknown')}\")\n",
    "        print(f\"   Topic: {doc.metadata.get('topic', 'Unknown')}\")\n",
    "        print()\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in similarity search: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1e8ecc",
   "metadata": {},
   "source": [
    "## 7. Similarity Search with Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7cafdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search with similarity scores\n",
    "query = \"How does PostgreSQL work with AI?\"\n",
    "\n",
    "try:\n",
    "    results_with_scores = vectorstore.similarity_search_with_score(query, k=3)\n",
    "    \n",
    "    print(f\"üîç Query: '{query}'\")\n",
    "    print(f\"üìä Found {len(results_with_scores)} documents with scores:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, (doc, score) in enumerate(results_with_scores, 1):\n",
    "        print(f\"{i}. Similarity Score: {score:.4f}\")\n",
    "        print(f\"   Content: {doc.page_content}\")\n",
    "        print(f\"   Source: {doc.metadata.get('source', 'Unknown')}\")\n",
    "        print(f\"   Topic: {doc.metadata.get('topic', 'Unknown')}\")\n",
    "        print()\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in similarity search with scores: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0c9bbf",
   "metadata": {},
   "source": [
    "## 8. Filter Search by Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6008338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search with metadata filter\n",
    "query = \"database systems\"\n",
    "\n",
    "try:\n",
    "    # Filter by topic\n",
    "    results = vectorstore.similarity_search(\n",
    "        query, \n",
    "        k=5,\n",
    "        filter={\"topic\": \"database\"}\n",
    "    )\n",
    "    \n",
    "    print(f\"üîç Query: '{query}' (filtered by topic: database)\")\n",
    "    print(f\"üìä Found {len(results)} filtered documents:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, doc in enumerate(results, 1):\n",
    "        print(f\"{i}. Content: {doc.page_content}\")\n",
    "        print(f\"   Metadata: {doc.metadata}\")\n",
    "        print()\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in filtered search: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0f41a8",
   "metadata": {},
   "source": [
    "## 9. Maximum Marginal Relevance (MMR) Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335fa164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMR search for diversity\n",
    "query = \"machine learning and databases\"\n",
    "\n",
    "try:\n",
    "    results = vectorstore.max_marginal_relevance_search(\n",
    "        query, \n",
    "        k=3,\n",
    "        fetch_k=10  # Fetch more documents for diversity\n",
    "    )\n",
    "    \n",
    "    print(f\"üîç MMR Query: '{query}'\")\n",
    "    print(f\"üìä Found {len(results)} diverse documents:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, doc in enumerate(results, 1):\n",
    "        print(f\"{i}. Content: {doc.page_content}\")\n",
    "        print(f\"   Source: {doc.metadata.get('source', 'Unknown')}\")\n",
    "        print(f\"   Topic: {doc.metadata.get('topic', 'Unknown')}\")\n",
    "        print()\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in MMR search: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae057f8",
   "metadata": {},
   "source": [
    "## 10. View Vector Store Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf09fd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get collection statistics\n",
    "try:\n",
    "    # Connect to database to get statistics\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Get document count\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT COUNT(*) \n",
    "        FROM langchain_pg_embedding \n",
    "        WHERE collection_id = (\n",
    "            SELECT uuid FROM langchain_pg_collection WHERE name = 'langchain_docs'\n",
    "        )\n",
    "    \"\"\")\n",
    "    \n",
    "    doc_count = cursor.fetchone()[0]\n",
    "    print(f\"üìä Vector Store Statistics:\")\n",
    "    print(f\"   Collection: langchain_docs\")\n",
    "    print(f\"   Documents: {doc_count}\")\n",
    "    print(f\"   Embedding Model: {embeddings.model_name}\")\n",
    "    \n",
    "    # Get sample embeddings\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT cembeddings \n",
    "        FROM langchain_pg_embedding \n",
    "        WHERE collection_id = (\n",
    "            SELECT uuid FROM langchain_pg_collection WHERE name = 'langchain_docs'\n",
    "        )\n",
    "        LIMIT 1\n",
    "    \"\"\")\n",
    "    \n",
    "    sample_embedding = cursor.fetchone()\n",
    "    if sample_embedding:\n",
    "        embedding_dim = len(sample_embedding[0])\n",
    "        print(f\"   Embedding Dimension: {embedding_dim}\")\n",
    "    \n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error getting statistics: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9752332",
   "metadata": {},
   "source": [
    "## 11. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cda185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up resources\n",
    "try:\n",
    "    if 'vectorstore' in locals():\n",
    "        # Note: PGVector doesn't have a close method, but we can clean up the collection\n",
    "        print(\"‚úÖ Vector store operations completed\")\n",
    "    \n",
    "    print(\"‚úÖ Notebook completed successfully!\")\n",
    "    print(\"\\nüìù Summary:\")\n",
    "    print(\"- Created PGVector store with LangChain\")\n",
    "    print(\"- Added sample documents with embeddings\")\n",
    "    print(\"- Performed similarity search operations\")\n",
    "    print(\"- Demonstrated metadata filtering\")\n",
    "    print(\"- Used MMR for diverse results\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during cleanup: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
